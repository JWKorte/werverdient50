{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "298410cc-8034-49c8-b651-a7b7935f6f76",
   "metadata": {},
   "source": [
    "# Version 1 mit metrischen und kategorialen Variablen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09db2ee4-0e0e-4e86-9223-660beb9fc03c",
   "metadata": {},
   "source": [
    "Import der benutzen Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f25d9b1-2786-437c-8a81-0d1179bf4f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arbeitsbibliotheken\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "# Visualisierungsbibliotheken\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Preprocessing/Evaluation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "# Mashine Learnung Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# Ensemble Learning Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "# Feature Importance\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b3cb7f-94f9-4272-b0c8-0c60244fa4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden der in Vorbereitung gespeicherten Datensätze\n",
    "censusdatatrain = pd.read_csv(\"adult.data\", index_col=0)\n",
    "censusdatatest = pd.read_csv(\"adult.test\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ce9df1-454a-4c0a-8524-fa977a761ffc",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8023d76-9a39-4a0a-997f-506775b6d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Split\n",
    "# Da der Datensatz bereits einen vorgefertigten Split mitliefert, wird auf Train_Test_Split verzichtet\n",
    "# Trainingsdaten\n",
    "X_train = censusdatatrain.drop(\"target\", axis=1) \n",
    "y_train = censusdatatrain[\"target\"].replace(\" >50K\",1).replace(\" <=50K\",0)\n",
    "# Testdaten\n",
    "X_test = censusdatatest.drop(\"target\", axis=1)\n",
    "y_test = censusdatatest[\"target\"].replace(\" >50K.\",1).replace(\" <=50K.\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a0fb20-26a7-4dbf-9ef6-ba2de53772cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing der Training- und Test-Daten\n",
    "for df in [X_train,X_test]:\n",
    "# workclass\n",
    "    df[\"workclass\"] = df[\"workclass\"].replace(to_replace=[\" Self-emp-not-inc\", \" Self-emp-inc\"], value=\"Selfemp\")\n",
    "    df[\"workclass\"] = df[\"workclass\"].replace(to_replace=[\" Local-gov\", \" State-gov\", \" Federal-gov\"], value=\"Goverm\")\n",
    "    df[\"workclass\"] = df[\"workclass\"].replace(to_replace=[\" ?\", \" Without-pay\", \" Never-worked\"], value=\"Residualwc\")\n",
    "# native country\n",
    "    df[\"native-country\"] = [1 if x==\" United-States\" or x==\" Outlying-US(Guam-USVI-etc)\" else 0 for x in df[\"native-country\"]]\n",
    "# marital-status\n",
    "    df[\"marital-status\"] = df[\"marital-status\"].replace(to_replace=[\" Married-civ-spouse\",\" Married-spouse-absent\",\" Married-AF-spouse\"], value=\"married\")\n",
    "    df[\"marital-status\"] = df[\"marital-status\"].replace(to_replace=[\" Divorced\",\" Seperated\",\" Widowed\"], value=\"seperated\")\n",
    "# race\n",
    "    df[\"race\"] = df[\"race\"].replace(to_replace=[\" Other\",\" Amer-Indian-Eskimo\",\" Asian-Pac-Islander\"], value=\"other_race\")\n",
    "# occupation\n",
    "    df[\"occupation\"] = df[\"occupation\"].replace(to_replace=[\" Armed-Forces\", \" Protective-serv\"], value=\"Security\")\n",
    "    df[\"occupation\"] = df[\"occupation\"].replace(to_replace=[\" Other-service\", \" Priv-house-serv\", \" ?\"], value=\"Other_Services\")\n",
    "# sex\n",
    "    df[\"sex\"] = [0 if x == \" Male\" else 1 for x in df[\"sex\"]]\n",
    "# Drop \n",
    "    df.drop([\"fnlwgt\", \"education\", \"relationship\"], axis=1, inplace=True)\n",
    "# Dummy-Variablen\n",
    "X_train = pd.concat([X_train.drop(\"workclass\", axis=1),pd.get_dummies(X_train[\"workclass\"])], axis=1)\n",
    "X_train = pd.concat([X_train.drop(\"occupation\", axis=1),pd.get_dummies(X_train[\"occupation\"])], axis=1)\n",
    "X_train = pd.concat([X_train.drop(\"marital-status\", axis=1),pd.get_dummies(X_train[\"marital-status\"])], axis=1)\n",
    "X_train = pd.concat([X_train.drop(\"race\", axis=1),pd.get_dummies(X_train[\"race\"])], axis=1)\n",
    "X_test = pd.concat([X_test.drop(\"marital-status\", axis=1),pd.get_dummies(X_test[\"marital-status\"])], axis=1)\n",
    "X_test = pd.concat([X_test.drop(\"workclass\", axis=1),pd.get_dummies(X_test[\"workclass\"])], axis=1)\n",
    "X_test = pd.concat([X_test.drop(\"occupation\", axis=1),pd.get_dummies(X_test[\"occupation\"])], axis=1) \n",
    "X_test = pd.concat([X_test.drop(\"race\", axis=1),pd.get_dummies(X_test[\"race\"])], axis=1) \n",
    "# Drop Dummy-Variablen\n",
    "for df in [X_train,X_test]:\n",
    "    df.drop([\"Residualwc\", \"Other_Services\", \" Never-married\", \" White\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26766edf-247c-4f73-8793-8b7a7f6de021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap und Korrelationsmatrix zur Überprüfung von Multikollinearität\n",
    "for x in [X_train, X_test]:\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    display(x.corr())\n",
    "for x in [X_train, X_test]:\n",
    "    plt.figure(figsize=(10,10))\n",
    "    sns.heatmap(x.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2038dc-1a51-415f-9c0b-c16f6be08eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Normalisieren der Daten\n",
    "features = X_train.columns\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a54375a-7526-47f6-8c99-f525bf074d8b",
   "metadata": {},
   "source": [
    "Maschine Learning Algorithmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee002685-94f7-4cf5-ad57-26641de91316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelbuilding Mashine-Learning Classifier\n",
    "# Decision Tree\n",
    "print(\"Decision Tree\")\n",
    "start_time = time.time()\n",
    "dtc = DecisionTreeClassifier() \n",
    "tree_para = {'criterion':['gini','entropy'],'max_depth':[i for i in range(2,23)], 'min_samples_split':[i for i in range (2,23)]}\n",
    "grd_clf = HalvingGridSearchCV(dtc, tree_para, scoring=\"f1\", cv=5, n_jobs=-1)\n",
    "grd_clf.fit(X_train, y_train)\n",
    "model_with_best_tree_parameters = grd_clf.best_estimator_\n",
    "btmodel = model_with_best_tree_parameters.fit(X_train,y_train)\n",
    "print(f'{\"Akkuranz: \" }{cross_val_score(btmodel,X_train,y_train,scoring=\"accuracy\",cv=10, n_jobs=-1).mean():.4f}')\n",
    "print(\"Modellparameter:\", btmodel.get_params())\n",
    "y_predict = btmodel.predict(X_test)\n",
    "print(classification_report(y_test,y_predict))\n",
    "print(f'{\"Berechnungszeit: \"}{time.time()-start_time:.2f}{\" Sekunden\"}')\n",
    "# Gaussian Naive Bayes \n",
    "print(\"Gaussian Naive Bayes\")\n",
    "start_time = time.time()\n",
    "gnb = GaussianNB()\n",
    "gnbmodel = gnb.fit(X_train,y_train)\n",
    "print(f'{\"Akkuranz: \" }{cross_val_score(gnbmodel,X_train,y_train,scoring=\"accuracy\",cv=5, n_jobs=-1).mean():.4f}')\n",
    "print(\"Modellparameter:\", gnbmodel.get_params())\n",
    "y_predict = gnbmodel.predict(X_test)\n",
    "print(classification_report(y_test,y_predict))\n",
    "print(f'{\"Berechnungszeit: \"}{time.time()-start_time:.2f}{\" Sekunden\"}')\n",
    "# Support Vector Mashine\n",
    "print(\"Support Vector Mashine\")\n",
    "start_time = time.time()\n",
    "svm = SVC()\n",
    "svm_para = {'kernel':['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "grd_clf = HalvingGridSearchCV(svm, svm_para, scoring=\"f1\", cv=5, n_jobs=-1)\n",
    "grd_clf.fit(X_train, y_train)\n",
    "model_with_best_svm_parameters = grd_clf.best_estimator_\n",
    "bsvmmodel = model_with_best_svm_parameters.fit(X_train,y_train)\n",
    "print(f'{\"Akkuranz: \" }{cross_val_score(bsvmmodel,X_train,y_train,scoring=\"accuracy\",cv=10, n_jobs=-1).mean():.4f}')\n",
    "print(\"Modellparameter:\", bsvmmodel.get_params())\n",
    "y_predict = bsvmmodel.predict(X_test)\n",
    "print(classification_report(y_test,y_predict))\n",
    "print(f'{\"Berechnungszeit: \"}{time.time()-start_time:.2f}{\" Sekunden\"}')\n",
    "# KNeighbor Classifier\n",
    "print(\"KNeighbor Classifier\")\n",
    "start_time = time.time()\n",
    "knc = KNeighborsClassifier()\n",
    "k_para = {\"weights\" : ['uniform', 'distance'], \"leaf_size\" : [i for i in np.random.randint(2,80,15)], \"n_neighbors\": [i for i in np.random.randint(2,40,5)]}\n",
    "k_grd_clf = HalvingGridSearchCV(knc, k_para, scoring=\"f1\", cv=5, n_jobs=-1)\n",
    "k_grd_clf.fit(X_train,y_train)\n",
    "model_with_best_k_parameters = k_grd_clf.best_estimator_\n",
    "bkmodel = model_with_best_k_parameters.fit(X_train,y_train)\n",
    "print(f'{\"Akkuranz: \" }{cross_val_score(bkmodel,X_train,y_train,scoring=\"accuracy\",cv=10, n_jobs=-1).mean():.4f}')\n",
    "print(\"Modellparameter:\", bkmodel.get_params())  \n",
    "y_predict = bkmodel.predict(X_test)\n",
    "print(classification_report(y_test,y_predict))\n",
    "print(f'{\"Berechnungszeit: \"}{time.time()-start_time:.2f}{\" Sekunden\"}')\n",
    "# Ridge Classifier\n",
    "print(\"Ridge Classifier\")\n",
    "start_time = time.time()\n",
    "rc = RidgeClassifier()\n",
    "rcmodel=rc.fit(X_train,y_train)\n",
    "y_predict = rcmodel.predict(X_test)\n",
    "print(f'{\"Akkuranz: \" }{cross_val_score(rcmodel,X_train,y_train,scoring=\"accuracy\",cv=10, n_jobs=-1).mean():.4f}')\n",
    "print(rcmodel.get_params())  \n",
    "print(classification_report(y_test,y_predict))\n",
    "print(f'{\"Berechnungszeit: \"}{time.time()-start_time:.2f}{\" Sekunden\"}')\n",
    "# Logistic Regression Classifier\n",
    "print(\"Logistic Regression Classifier\")\n",
    "start_time = time.time()\n",
    "lr = LogisticRegressionCV(cv=5)\n",
    "lrmodel = lr.fit(X_train,y_train)\n",
    "y_predict = lrmodel.predict(X_test)\n",
    "print(f'{\"Akkuranz: \" }{cross_val_score(lrmodel,X_train,y_train,scoring=\"accuracy\",cv=10, n_jobs=-1).mean():.4f}')\n",
    "print(\"Modellparameter:\", lrmodel.get_params())  \n",
    "print(classification_report(y_test,y_predict))\n",
    "print(f'{\"Berechnungszeit: \"}{time.time()-start_time:.2f}{\" Sekunden\"}')\n",
    "# Linear Discriminant Classifier\n",
    "print(\"Linear Discriminant Classifier\")\n",
    "start_time = time.time()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "ldamodel = lda.fit(X_train,y_train)\n",
    "y_predict = ldamodel.predict(X_test)\n",
    "print(f'{\"Akkuranz: \" }{cross_val_score(ldamodel,X_train,y_train,scoring=\"accuracy\",cv=10, n_jobs=-1).mean():.4f}')\n",
    "print(\"Modellparameter:\", ldamodel.get_params())  \n",
    "print(classification_report(y_test,y_predict))\n",
    "print(f'{\"Berechnungszeit: \"}{time.time()-start_time:.2f}{\" Sekunden\"}')\n",
    "# MLP Classifier\n",
    "print(\"MLP Classifier\")\n",
    "start_time = time.time()\n",
    "mlp = MLPClassifier()\n",
    "mlp_para = {\"max_iter\" : [i for i in [300,400]], \"learning_rate_init\": [i for i in [0.01,0.001,0.0001]], \"hidden_layer_sizes\": [i for i in [(100,),(50,),(200,),(50,25),(100,50,25),(50,100,50,25)]]}\n",
    "mlp_grd_clf = HalvingGridSearchCV(mlp, mlp_para, scoring=\"f1\", cv=5, n_jobs=-1)\n",
    "mlp_grd_clf.fit(X_train,y_train)\n",
    "model_with_best_mlp_parameters = mlp_grd_clf.best_estimator_\n",
    "bmlpmodel = model_with_best_mlp_parameters.fit(X_train,y_train)\n",
    "print(f'{\"Akkuranz: \" }{cross_val_score(bmlpmodel,X_train,y_train,scoring=\"accuracy\",cv=10, n_jobs=-1).mean():.4f}')\n",
    "print(bmlpmodel.get_params())   \n",
    "y_predict = bmlpmodel.predict(X_test)\n",
    "print(classification_report(y_test,y_predict))\n",
    "print(f'{\"Berechnungszeit: \"}{time.time()-start_time:.2f}{\" Sekunden\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ed7170-9ffa-452e-82bc-ba168f52be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roc-Graph Vergleich\n",
    "ax = plt.gca()\n",
    "plot_roc_curve(btmodel,X_test,y_test,ax=ax)\n",
    "plot_roc_curve(gnbmodel,X_test,y_test,ax=ax)\n",
    "plot_roc_curve(bsvmmodel,X_test,y_test,ax=ax)\n",
    "plot_roc_curve(bkmodel,X_test,y_test,ax=ax)\n",
    "plot_roc_curve(rcmodel,X_test,y_test,ax=ax)\n",
    "plot_roc_curve(lrmodel,X_test,y_test,ax=ax)\n",
    "plot_roc_curve(ldamodel,X_test,y_test,ax=ax)\n",
    "plot_roc_curve(bmlpmodel,X_test,y_test,ax=ax)\n",
    "plt.savefig(\"roc_model.png\")\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39992bde-82de-404d-bf44-87b43b6d6001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Feature Importance Training\n",
    "model_list = [btmodel,gnbmodel,bsvmmodel,bkmodel,rcmodel,lrmodel,ldamodel,bmlpmodel]\n",
    "file_list=[\"bt.png\",\"gnb.png\",\"bsv.png\",\"bk.png\",\"rc.png\",\"lr.png\",\"lda.png\",\"bml.png\"]\n",
    "for model, file in zip(model_list,file_list):\n",
    "    start_time = time.time()\n",
    "    result = permutation_importance(model, X_train, y_train, n_jobs=-1)\n",
    "    model_importances = pd.Series(result.importances_mean, index=features)\n",
    "    model_importances.plot.bar(yerr=result.importances_std)\n",
    "    print(model)\n",
    "    print(f'{\"Berechnungszeit: \"}{time.time()-start_time:.2f}{\" Sekunden\"}')\n",
    "    plt.savefig(file)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91458c47-7acb-457a-9b38-122d3f8e56d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Feature Importance Test\n",
    "model_list = [btmodel,gnbmodel,bsvmmodel,bkmodel,rcmodel,lrmodel,ldamodel,bmlpmodel]\n",
    "file_list=[\"btb.png\",\"gnbb.png\",\"bsvb.png\",\"bkb.png\",\"rcb.png\",\"lrb.png\",\"ldab.png\",\"bmlb.png\"]\n",
    "for model, file in zip(model_list,file_list):\n",
    "    start_time = time.time()\n",
    "    result = permutation_importance(model, X_test, y_test, n_jobs=-1)\n",
    "    model_importances = pd.Series(result.importances_mean, index=features)\n",
    "    model_importances.plot.bar(yerr=result.importances_std)\n",
    "    print(model)\n",
    "    print(f'{\"Berechnungszeit: \"}{time.time()-start_time:.2f}{\" Sekunden\"}')\n",
    "    plt.savefig(file)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec65fa1-1436-49ba-b903-c0433d804fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble Learning\n",
    "# Random Forest\n",
    "start_time = time.time()\n",
    "print(\"Random Forest\")\n",
    "rfc = RandomForestClassifier()\n",
    "tree_para = {'criterion':['gini','entropy'],'n_estimators': [i for i in [100,200,500,1000]]}\n",
    "grd_clf = HalvingGridSearchCV(rfc, tree_para, cv=5, n_jobs=-1)\n",
    "grd_clf.fit(X_train, y_train)\n",
    "model_with_best_rfc_parameters = grd_clf.best_estimator_\n",
    "brfcmodel = model_with_best_rfc_parameters.fit(X_train,y_train)\n",
    "print(f'{\"Akkuranz: \" }{cross_val_score(brfcmodel,X_train,y_train,scoring=\"accuracy\",cv=10, n_jobs=-1).mean():.4f}')\n",
    "print(brfcmodel.get_params())\n",
    "y_predict = brfcmodel.predict(X_test)\n",
    "print(classification_report(y_test,y_predict))\n",
    "print(f'{\"Berechnungszeit: \"}{time.time()-start_time:.2f}{\" Sekunden\"}')\n",
    "# Gradient Boosting\n",
    "start_time = time.time()\n",
    "print(\"Gradient Boosting\")\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc_para = {'n_estimators': [i for i in [50,100,500,1000]],'learning_rate': [i for i in [0.01,0.1,0.2]]}\n",
    "grd_clf = HalvingGridSearchCV(gbc, gbc_para, scoring=\"f1\", cv=5, n_jobs=-1)\n",
    "grd_clf.fit(X_train, y_train)\n",
    "model_with_best_gbc_parameters = grd_clf.best_estimator_\n",
    "bgbcmodel = model_with_best_gbc_parameters.fit(X_train,y_train)\n",
    "print(f'{\"Akkuranz: \" }{cross_val_score(bgbcmodel,X_train,y_train,scoring=\"accuracy\",cv=10,n_jobs=-1).mean():.4f}')\n",
    "print(bgbcmodel.get_params())\n",
    "y_predict = bgbcmodel.predict(X_test)\n",
    "print(classification_report(y_test,y_predict))\n",
    "print(f'{\"Berechnungszeit: \"}{time.time()-start_time:.2f}{\" Sekunden\"}')\n",
    "# Bagging\n",
    "start_time = time.time()\n",
    "print(\"Bagging Classifier\")\n",
    "bc = BaggingClassifier()\n",
    "bcmodel = bc.fit(X_train,y_train)\n",
    "y_predict = bcmodel.predict(X_test)\n",
    "print(f'{\"Akkuranz: \" }{cross_val_score(bcmodel,X_train,y_train,scoring=\"accuracy\",cv=10,n_jobs=-1).mean():.4f}')\n",
    "print(bcmodel.get_params())  \n",
    "print(classification_report(y_test,y_predict))\n",
    "print(f'{\"Berechnungszeit: \"}{time.time()-start_time:.2f}{\" Sekunden\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad38b9cb-5fd7-4429-8dff-600ab0b2855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roc-Graph Vergleich Ensemble\n",
    "ax = plt.gca()\n",
    "plot_roc_curve(brfcmodel,X_test,y_test,ax=ax)\n",
    "plot_roc_curve(bgbcmodel,X_test,y_test,ax=ax)\n",
    "plot_roc_curve(bcmodel,X_test,y_test,ax=ax)\n",
    "plt.savefig(\"roc_emodel.png\")\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f580cea-db22-4e7b-9748-38b57ace7d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Feature Importance Ensemble Training\n",
    "emodel_list=[brfcmodel,bgbcmodel,bcmodel]\n",
    "file_list=[\"brf.png\",\"bgb.png\",\"bc.png\"]\n",
    "for model, file in zip(emodel_list, file_list):\n",
    "    start_time = time.time()\n",
    "    result = permutation_importance(model, X_train, y_train, n_jobs=-1)\n",
    "    model_importances = pd.Series(result.importances_mean, index=features)\n",
    "    model_importances.plot.bar(yerr=result.importances_std)\n",
    "    print(model)\n",
    "    print(f'{\"Berechnungszeit: \"}{time.time()-start_time:.2f}{\" Sekunden\"}')\n",
    "    plt.savefig(file)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aac6e3c-1b4e-4e7c-a0d8-d90d7b9431ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Feature Importance Ensemble Test\n",
    "emodel_list=[brfcmodel,bgbcmodel,bcmodel]\n",
    "file_list=[\"brfb.png\",\"bgbb.png\",\"bcb.png\"]\n",
    "for model, file in zip(emodel_list, file_list):\n",
    "    start_time = time.time()\n",
    "    result = permutation_importance(model, X_test, y_test, n_jobs=-1)\n",
    "    model_importances = pd.Series(result.importances_mean, index=features)\n",
    "    model_importances.plot.bar(yerr=result.importances_std)\n",
    "    print(model)\n",
    "    print(f'{\"Berechnungszeit: \"}{time.time()-start_time:.2f}{\" Sekunden\"}')\n",
    "    plt.savefig(file)\n",
    "    plt.show(block=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
